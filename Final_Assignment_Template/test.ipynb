{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('metadata.jsonl', 'r') as f: \n",
    "    json_list = list(f)\n",
    "\n",
    "json_QA = []\n",
    "for json_str in json_list: \n",
    "    json_data = json.loads(json_str)\n",
    "    json_QA.append(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Task ID: 99c9cc74-fdc8-46c6-8f8d-3ce2d3bfeea3\n",
      "Question: Hi, I'm making a pie but I could use some help with my shopping list. I have everything I need for the crust, but I'm not sure about the filling. I got the recipe from my friend Aditi, but she left it as a voice memo and the speaker on my phone is buzzing so I can't quite make out what she's saying. Could you please listen to the recipe and list all of the ingredients that my friend described? I only want the ingredients for the filling, as I have everything I need to make my favorite pie crust. I've attached the recipe as Strawberry pie.mp3.\n",
      "\n",
      "In your response, please only list the ingredients, not any measurements. So if the recipe calls for \"a pinch of salt\" or \"two cups of ripe strawberries\" the ingredients on the list would be \"salt\" and \"ripe strawberries\".\n",
      "\n",
      "Please format your response as a comma separated list of ingredients. Also, please alphabetize the ingredients.\n",
      "Level: 1\n",
      "Final Answer: cornstarch, freshly squeezed lemon juice, granulated sugar, pure vanilla extract, ripe strawberries\n",
      "Annotator Metadata: \n",
      "  ├── Steps: \n",
      "  │      ├── Step 1: Load the file supplied to me by my user.\n",
      "  │      ├── Step 2: Using speech-to-text tools, convert the audio file to plain text and store it for the candidate word list:\n",
      "  │      ├── \n",
      "  │      ├── \"In a saucepan, combine ripe strawberries, granulated sugar, freshly squeezed lemon juice, and cornstarch. Cook the mixture over medium heat, stirring constantly, until it thickens to a smooth consistency. Remove from heat and stir in a dash of pure vanilla extract. Allow the strawberry pie filling to cool before using it as a delicious and fruity filling for your pie crust.\"\n",
      "  │      ├── \n",
      "  │      ├── Step 3: Evaluate the candidate word list and process it, stripping each ingredient encountered to a provisional response list:\n",
      "  │      ├── \n",
      "  │      ├── ripe strawberries\n",
      "  │      ├── granulated sugar\n",
      "  │      ├── freshly squeezed lemon juice\n",
      "  │      ├── cornstarch\n",
      "  │      ├── pure vanilla extract\n",
      "  │      ├── \n",
      "  │      ├── Step 4: Alphabetize the list of ingredients as requested by my user to create a finalized response:\n",
      "  │      ├── \n",
      "  │      ├── cornstarch\n",
      "  │      ├── freshly squeezed lemon juice\n",
      "  │      ├── granulated sugar\n",
      "  │      ├── pure vanilla extract\n",
      "  │      ├── ripe strawberries\n",
      "  │      ├── \n",
      "  │      ├── Step 5: Report the correct response to my user:\n",
      "  │      ├── \n",
      "  │      ├── \"cornstarch\n",
      "  │      ├── freshly squeezed lemon juice\n",
      "  │      ├── granulated sugar\n",
      "  │      ├── pure vanilla extract\n",
      "  │      ├── ripe strawberries\"\n",
      "  ├── Number of steps: 5\n",
      "  ├── How long did this take?: 3 minutes\n",
      "  ├── Tools:\n",
      "  │      ├── 1. A file interface\n",
      "  │      ├── 2. A speech-to-text tool\n",
      "  └── Number of tools: 2\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_samples = random.sample(json_QA, 1)\n",
    "for sample in random_samples:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Task ID: {sample['task_id']}\")\n",
    "    print(f\"Question: {sample['Question']}\")\n",
    "    print(f\"Level: {sample['Level']}\")\n",
    "    print(f\"Final Answer: {sample['Final answer']}\")\n",
    "    print(f\"Annotator Metadata: \")\n",
    "    print(f\"  ├── Steps: \")\n",
    "    for step in sample['Annotator Metadata']['Steps'].split('\\n'):\n",
    "        print(f\"  │      ├── {step}\")\n",
    "    print(f\"  ├── Number of steps: {sample['Annotator Metadata']['Number of steps']}\")\n",
    "    print(f\"  ├── How long did this take?: {sample['Annotator Metadata']['How long did this take?']}\")\n",
    "    print(f\"  ├── Tools:\")\n",
    "    for tool in sample['Annotator Metadata']['Tools'].split('\\n'):\n",
    "        print(f\"  │      ├── {tool}\")\n",
    "    print(f\"  └── Number of tools: {sample['Annotator Metadata']['Number of tools']}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from dotenv import load_dotenv \n",
    "import os \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (0.3.56)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langchain-core) (0.3.34)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langchain-core) (2.10.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.27.2)\n",
      "Requirement already satisfied: anyio in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\projects\\rag_poc\\agents_course_hf\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss \n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore \n",
    "from langchain_community.vectorstores import FAISS \n",
    "\n",
    "embedding_dim = len(embeddings.embed_query(\"hello world\"))\n",
    "index = faiss.IndexFlatL2(embedding_dim) \n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings, \n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore({}), \n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 165 documents to the vector store.\n"
     ]
    }
   ],
   "source": [
    "# Add items to vector store \n",
    "\n",
    "from uuid import uuid4 \n",
    "from langchain_core.documents import Document \n",
    "\n",
    "docs = []\n",
    "\n",
    "for sample in json_QA:\n",
    "    content = f\"Question: {sample['Question']}\\n\\nFinal answer: {sample['Final answer']}\"\n",
    "    doc = Document(\n",
    "        page_content=content,\n",
    "        metadata={\n",
    "            \"source\": sample[\"task_id\"],\n",
    "            \"level\": sample[\"Level\"]\n",
    "        }\n",
    "    )\n",
    "    docs.append(doc)\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(docs))]\n",
    "\n",
    "vector_store.add_documents(documents=docs, ids=uuids)\n",
    "print(f\"Added {len(docs)} documents to the vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(\"vector_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='eafe1a17-a3f9-444b-9119-6c96f40915b8', metadata={'source': '840bfca7-4f7b-481a-8794-c560c340185d', 'level': 1}, page_content='Question: On June 6, 2023, an article by Carolyn Collins Petersen was published in Universe Today. This article mentions a team that produced a paper about their observations, linked at the bottom of the article. Find this paper. Under what NASA award number was the work performed by R. G. Arendt supported by?\\n\\nFinal answer: 80GSFC21M0002'),\n",
       " Document(id='a17c8559-b10c-4e7b-8f5f-472d24b0fe3c', metadata={'source': '0bdb7c40-671d-4ad1-9ce3-986b159c0ddc', 'level': 3}, page_content=\"Question: In NASA's Astronomy Picture of the Day on 2006 January 21, two astronauts are visible, with one appearing much smaller than the other. As of August 2023, out of the astronauts in the NASA Astronaut Group that the smaller astronaut was a member of, which one spent the least time in space, and how many minutes did he spend in space, rounded to the nearest minute? Exclude any astronauts who did not spend any time in space. Give the last name of the astronaut, separated from the number of minutes by a semicolon.\\n\\nFinal answer: White; 5876\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"On June 6, 2023, an article by Carolyn Collins Petersen was published in Universe Today. This article mentions a team that produced a paper about their observations, linked at the bottom of the article. Find this paper. Under what NASA award number was the work performed by R. G. Arendt supported by?\"\n",
    "\n",
    "\n",
    "vector_store.similarity_search(\n",
    "    query,\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='eafe1a17-a3f9-444b-9119-6c96f40915b8', metadata={'source': '840bfca7-4f7b-481a-8794-c560c340185d', 'level': 1}, page_content='Question: On June 6, 2023, an article by Carolyn Collins Petersen was published in Universe Today. This article mentions a team that produced a paper about their observations, linked at the bottom of the article. Find this paper. Under what NASA award number was the work performed by R. G. Arendt supported by?\\n\\nFinal answer: 80GSFC21M0002')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 1}) \n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_loaded = FAISS.load_local(\"vector_store\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='66eabedd-7236-4f0f-8996-5ca2c88f2779', metadata={'source': '840bfca7-4f7b-481a-8794-c560c340185d', 'level': 1}, page_content='Question: On June 6, 2023, an article by Carolyn Collins Petersen was published in Universe Today. This article mentions a team that produced a paper about their observations, linked at the bottom of the article. Find this paper. Under what NASA award number was the work performed by R. G. Arendt supported by?\\n\\nFinal answer: 80GSFC21M0002')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from re import search\n",
    "\n",
    "\n",
    "vector_store_loaded.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 1}).invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
